{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":229,"status":"ok","timestamp":1658777915515,"user":{"displayName":"Renzo Pacheco","userId":"14372041684715591073"},"user_tz":300},"id":"yUGfLkhpovH9","trusted":true},"outputs":[],"source":["#Vars\n","input_size = 256\n","batch_size = 16\n","train_size = 8000\n","validation_size = 1000\n","test_size = 1000\n","learning_rate = 0.001\n","epochs = 10\n","dropout = 0.0\n","dense_size = 1024"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1658777916683,"user":{"displayName":"Renzo Pacheco","userId":"14372041684715591073"},"user_tz":300},"id":"xwE4IxBFfGS4","trusted":true},"outputs":[],"source":["import os\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","import os \n","import datetime\n","\n","fruit = \"apple\"\n","model_current = \"vgg16\"\n","\n","file_name = f'{model_current}_{fruit}_{batch_size}_{epochs}_{dropout}'\n","log_dir = f'logs/fit/{model_current}_{fruit}_{batch_size}_{epochs}_{dropout}'\n","run_dir = f'./{model_current}_{fruit}_{batch_size}_{epochs}_{dropout}/'\n","os.makedirs(run_dir, exist_ok=True)\n","os.makedirs(log_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1965,"status":"ok","timestamp":1658777920811,"user":{"displayName":"Renzo Pacheco","userId":"14372041684715591073"},"user_tz":300},"id":"zp7Wct1Ch5mP","trusted":true},"outputs":[],"source":["from keras.applications.vgg16 import VGG16\n","\n","pre_trained_model = VGG16(\n","    input_shape = (input_size,input_size,3),\n","    include_top = False,\n","    weights='imagenet'\n",")\n","\n","for layer in pre_trained_model.layers:\n","  layer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":222,"status":"ok","timestamp":1658777923722,"user":{"displayName":"Renzo Pacheco","userId":"14372041684715591073"},"user_tz":300},"id":"kChkJkELjQAH","trusted":true},"outputs":[],"source":["from tensorflow.keras.optimizers import RMSprop\n","\n","#Flatten\n","x = layers.Flatten()(pre_trained_model.output)\n","\n","#Fully connected layer con 1024 hidden units y ReLU\n","x = layers.Dense(dense_size, activation='relu')(x)\n","#Dropout rate\n","if (dropout>0):\n","    x = layers.Dropout(dropout)(x)\n","x = layers.Dense(dense_size/2, activation='relu')(x)\n","\n","#Función de clasificación softmax - Clasificación binaria\n","x = layers.Dense(2, activation='softmax')(x)\n","\n","model = Model(pre_trained_model.input,x)\n","\n","model.compile(optimizer = RMSprop(learning_rate=learning_rate),\n","              loss='categorical_crossentropy',\n","              metrics = [tf.keras.metrics.Accuracy(name='accuracy'),\n","                         tf.keras.metrics.Precision(name='precision'), \n","                         tf.keras.metrics.Recall(name='recall')])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":998,"status":"ok","timestamp":1658777927227,"user":{"displayName":"Renzo Pacheco","userId":"14372041684715591073"},"user_tz":300},"id":"xqJgrTcPmNaO","outputId":"c4c0d0c1-316f-41e9-b34e-dadf8af34668","trusted":true},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale = 1./255.)\n","validation_datagen = ImageDataGenerator(rescale = 1./255.)\n","test_datagen = ImageDataGenerator(rescale = 1./255.)\n","\n","train_dir = f'../input/fruit-defect-dataset/FRUIT_DEFECT_TRAINING_DATASET/{fruit.upper()}/TRAIN'\n","validation_dir = f'../input/fruit-defect-dataset/FRUIT_DEFECT_TRAINING_DATASET/{fruit.upper()}/VALIDATION'\n","test_dir = f'../input/fruit-defect-dataset/FRUIT_DEFECT_TRAINING_DATASET/{fruit.upper()}/TEST'\n","\n","train_generator = train_datagen.flow_from_directory(train_dir,batch_size=batch_size,shuffle=True, class_mode = 'categorical', target_size=(input_size,input_size), seed=42)\n","validation_generator = validation_datagen.flow_from_directory(validation_dir,batch_size=batch_size,shuffle=False, class_mode = 'categorical', target_size=(input_size,input_size))\n","test_generator = test_datagen.flow_from_directory(test_dir,batch_size=batch_size,shuffle=False, class_mode = 'categorical', target_size=(input_size,input_size))\n","\n","labels = train_generator.class_indices\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0XGS_wsIFl8","outputId":"f46a9852-dbb1-4663-c639-bb31aa1bf595","trusted":true},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint\n","import tensorflow as tf\n","checkpoint = ModelCheckpoint(f\"{run_dir}{file_name}.h5\", monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","callbacks_list = [checkpoint, tensorboard_callback]\n","\n","\n","\n","history = model.fit(\n","    train_generator,\n","    validation_data = validation_generator,\n","    steps_per_epoch = train_size/batch_size,\n","    epochs = epochs,\n","    validation_steps = validation_size/batch_size,\n","    verbose = 1,\n","    callbacks = callbacks_list\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":726,"status":"ok","timestamp":1658247641243,"user":{"displayName":"Renzo Pacheco","userId":"14372041684715591073"},"user_tz":300},"id":"14XQiW0YJeuF","outputId":"2401185a-346b-4312-e7bb-988632cf9c68","trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","precision = history.history['precision']\n","val_precision = history.history['val_precision']\n","recall = history.history['recall']\n","val_recall = history.history['val_recall']\n","\n","n_epochs = range(len(acc))\n","\n","plt.plot(acc)\n","plt.plot(val_acc)\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend([\"Train\", 'Validation'], loc = 'upper left')\n","plt.savefig(f\"{run_dir}accuracy.jpg\")\n","plt.figure()\n","\n","plt.plot(loss)\n","plt.plot(val_loss)\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend([\"Train\", 'Validation'], loc = 'upper left')\n","plt.savefig(f\"{run_dir}loss.jpg\")\n","plt.figure()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-KAU0cH9qxRo","trusted":true},"outputs":[],"source":["import csv\n","\n","header = [\"train_acc\", \"val_acc\", \"train_loss\", \"val_loss\", \"train_precision\", \"val_precision\", \"train_recall\", \"val_recall\"]\n","\n","with open(f'{run_dir}metrics.csv', 'w', encoding='UTF8', newline='') as f:\n","    writer = csv.writer(f)\n","\n","    # write the header\n","    writer.writerow(header)\n","    for idx in range(len(acc)):\n","        line = [acc[idx],val_acc[idx],loss[idx],val_loss[idx], precision[idx], val_precision[idx], recall[idx], val_recall[idx]]        \n","        writer.writerow(line)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv(f'{run_dir}metrics.csv')\n","print('Best Metrics')\n","print(df.loc[df['val_acc'].idxmax()])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["results = model.evaluate(test_generator, verbose=1)\n","print('Test Accuracy: ', results[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!zip -r \"{file_name}_run.zip\" \"{run_dir}\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!zip -r \"{file_name}_logs.zip\" \"{log_dir}\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from IPython.display import FileLink\n","\n","FileLink(f\"{file_name}_run.zip\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from IPython.display import FileLink\n","FileLink(f\"{file_name}_logs.zip\")"]},{"cell_type":"markdown","metadata":{},"source":["Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install progress"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.preprocessing import image\n","# Helper libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from progress.bar import Bar\n","#from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","\n","#fresh_dir = 'test/fresh'\n","#defect_dir = 'test/defect'\n","\n","fresh_dir = f'../input/fruit-defect-dataset/FRUIT_DEFECT_TRAINING_DATASET/{fruit.upper()}/TEST/FRESH'\n","defect_dir = f'../input/fruit-defect-dataset/FRUIT_DEFECT_TRAINING_DATASET/{fruit.upper()}/TEST/DEFECT'\n","\n","fresh_files = os.listdir(fresh_dir)\n","defect_files = os.listdir(defect_dir)\n","\n","model = keras.models.load_model(f'{run_dir}{file_name}.h5')\n","\n","count_fresh_right = 0\n","count_fresh_wrong = 0\n","count_defect_right = 0\n","count_defect_wrong = 0\n","\n","bar = Bar('Processing', max=len(fresh_files)+len(defect_files))\n","for file in fresh_files:\n","    bar.next()\n","    img = image.load_img(fresh_dir+'/'+file, target_size=(input_size, input_size))\n","    img_array = keras.preprocessing.image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    classes = model.predict(preprocess_input(img_array))\n","    if classes[0][0]>0.5:\n","        count_fresh_wrong += 1\n","    elif classes[0][1]>0.5:\n","        count_fresh_right += 1\n","\n","for file in defect_files:\n","    bar.next()\n","    img = image.load_img(defect_dir+'/'+file, target_size=(256, 256))\n","    img_array = keras.preprocessing.image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    classes = model.predict(preprocess_input(img_array))\n","\n","    if classes[0][0]>0.5:\n","        count_defect_right += 1\n","    elif classes[0][1]>0.5:\n","        count_defect_wrong += 1\n","\n","bar.finish()\n","print(\"Fresh right: \", count_fresh_right)\n","print(\"Fresh wrong: \", count_fresh_wrong)\n","print(\"Defect right: \", count_defect_right)\n","print(\"Defect wrong: \", count_defect_wrong)\n","print(\"Acc: \", count_fresh_right+count_defect_right)"]},{"cell_type":"markdown","metadata":{},"source":["Export local"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"b557d93b90dea5d953ffe58baaf56f06fde2ccb3654250b20605f3f147789a19"}}},"nbformat":4,"nbformat_minor":4}
