{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GHJkeI7ikNV"
      },
      "source": [
        "**Import dependecies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "%conda install -c apple tensorflow-deps scipy #macos\n",
        "%pip install tensorflow-macos tensorflow-metal #macos\n",
        "\n",
        "%pip install --upgrade tensorflow \n",
        "%pip install pydot graphviz\n",
        "\n",
        "%pip install pandas numpy pillow matplotlib scipy autopep8 pydot\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.config.list_physical_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJiLL0VGe_wI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "import datetime\n",
        "\n",
        "fruit = \"apple\"\n",
        "model_current = \"vgg16\"\n",
        "curr_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "run_prefix = f'./runs/{fruit}/{model_current}/{curr_datetime}/'\n",
        "#results_prefix = f'./results/{fruit}/{model_current}/{curr_datetime}/'\n",
        "log_dir = f'logs/fit/{fruit}/{model_current}/{curr_datetime}'\n",
        "os.makedirs(run_prefix, exist_ok=True)\n",
        "#os.makedirs(results_prefix, exist_ok=True)\n",
        "run_prefix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XFtXmuTisRa"
      },
      "source": [
        "**Create an imagedatagenerator object to label data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nhMVi8sc-iA",
        "outputId": "d3b3b177-4001-4d64-8e4a-e1efd77dbb9b"
      },
      "outputs": [],
      "source": [
        "input_size = 224\n",
        "batch_size = 16\n",
        "train_size = 8000\n",
        "test_size = 2000\n",
        "learning_rate = 0.001\n",
        "epochs = 25\n",
        "dropout = 0.5\n",
        "dense_size = 1024\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "train_dir = f\"./dataset_frutas_colab/{fruit}/train\"\n",
        "test_dir = f\"./dataset_frutas_colab/{fruit}/test\"\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,batch_size=batch_size,class_mode = 'categorical', shuffle= True, target_size=(input_size,input_size), seed=42)\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,batch_size=batch_size,class_mode = 'categorical',shuffle= False, target_size=(input_size,input_size))\n",
        "train_generator.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "VGG16 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge7tchaKGh9C"
      },
      "outputs": [],
      "source": [
        "pre_trained_model = VGG16(\n",
        "    input_shape = (input_size,input_size,3),\n",
        "    include_top = False,\n",
        "    weights='imagenet'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efoR8KpwGa-i"
      },
      "source": [
        "Start transfer learning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucb7feWOGt3h"
      },
      "outputs": [],
      "source": [
        "#Flatten\n",
        "x = layers.Flatten()(pre_trained_model.output)\n",
        "#Fully connected layer con 1,024 hidden units y ReLU\n",
        "x = layers.Dense(dense_size, activation='relu')(x)\n",
        "x = layers.Dense(dense_size/2, activation='relu')(x)\n",
        "#Dropout rate\n",
        "if (dropout>0):\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "#Binary classification and softmax\n",
        "x = layers.Dense(2,activation='softmax')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input,x)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = [tf.keras.metrics.Accuracy(),\n",
        "                         tf.keras.metrics.Precision(), \n",
        "                         tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file=f\"{run_prefix}model.png\",\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=True,\n",
        "    dpi=96,\n",
        "    layer_range=None,\n",
        "    show_layer_activations=True,\n",
        ")\n",
        "print(\"Saved Model Image\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRJn0TwfHCGr",
        "outputId": "5e1c64ab-847d-4dae-94c3-96726d624c0c"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = test_generator,\n",
        "    steps_per_epoch = train_size/batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_steps = test_size/batch_size,\n",
        "    callbacks=[tensorboard_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRX7r_azHO4N"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "precision = history.history['precision']\n",
        "recall = history.history['recall']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.savefig(f\"{run_prefix}acc.svg\")\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig(f\"{run_prefix}loss.svg\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDCPxBt6HKOf"
      },
      "outputs": [],
      "source": [
        "model.save(f\"{run_prefix}{model_current}.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "header = [\"train_acc\", \"val_acc\", \"train_loss\", \"val_loss\", \"precision\", \"recall\"]\n",
        "\n",
        "with open(f'{run_prefix}{epochs}-{dropout}-{batch_size}-{learning_rate}-{input_size}-RMS-metrics.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    # write the header\n",
        "    writer.writerow(header)\n",
        "    for idx in range(len(acc)):\n",
        "        line = [acc[idx],val_acc[idx],loss[idx],val_loss[idx], precision[idx], recall[idx]]        \n",
        "        writer.writerow(line)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Probar la prediccion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TensorFlow and tf.keras\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "# Helper libraries\n",
        "\n",
        "fresh_dir = './test_apple/fresh'\n",
        "defect_dir = './test_apple/defect'\n",
        "\n",
        "fresh_files = os.listdir(fresh_dir)\n",
        "defect_files = os.listdir(defect_dir)\n",
        "\n",
        "#model = keras.models.load_model('mobilenetv2_16_30_0.2.h5')\n",
        "\n",
        "count_fresh_right = 0\n",
        "count_fresh_wrong = 0\n",
        "count_defect_right = 0\n",
        "count_defect_wrong = 0\n",
        "\n",
        "fresh_prob = []\n",
        "defect_prob = []\n",
        "\n",
        "for file in fresh_files:\n",
        "    img = tf.keras.utils.load_img(\n",
        "        fresh_dir+'/'+file, target_size=(input_size, input_size))\n",
        "    img_array = tf.keras.utils.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    images = np.vstack([img_array])\n",
        "    classes = model.predict(images, batch_size=batch_size)\n",
        "    fresh_prob.append((classes[0][0], classes[0][1]))\n",
        "    if classes[0][0] > 0.5:\n",
        "        count_fresh_wrong += 1\n",
        "    elif classes[0][1] > 0.5:\n",
        "        count_fresh_right += 1\n",
        "\n",
        "\n",
        "for file in defect_files:\n",
        "    img = tf.keras.utils.load_img(\n",
        "        defect_dir+'/'+file, target_size=(input_size, input_size))\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    images = np.vstack([img_array])\n",
        "    classes = model.predict(images, batch_size=batch_size)\n",
        "    defect_prob.append((classes[0][0], classes[0][1]))\n",
        "    if classes[0][0] > 0.5:\n",
        "        count_defect_right += 1\n",
        "    elif classes[0][1] > 0.5:\n",
        "        count_defect_wrong += 1\n",
        "\n",
        "\n",
        "print(\"Fresh right: \", count_fresh_right)\n",
        "print(\"Fresh wrong: \", count_fresh_wrong)\n",
        "print(\"Defect right: \", count_defect_right)\n",
        "print(\"Defect wrong: \", count_defect_wrong)\n",
        "\n",
        "\n",
        "with open(f'{run_prefix}{epochs}-{dropout}-{batch_size}-{learning_rate}-{input_size}-RMS-predicction.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    # write the header1\n",
        "    writer.writerow([\"fresh_right\", \"fresh_wrong\",\n",
        "                    \"defect_right\", \"defect_wrong\"])\n",
        "    writer.writerow([count_fresh_right, count_fresh_wrong,\n",
        "                    count_defect_right, count_defect_wrong])\n",
        "    # write the header2\n",
        "    writer.writerow([\"fresh_negative\", \"fresh_positive\",\n",
        "                    \"defect_positive\", \"defect_negative\"])\n",
        "    for idx in range(len(fresh_prob)):\n",
        "        writer.writerow([fresh_prob[idx][0], fresh_prob[idx][1],\n",
        "                        defect_prob[idx][0], defect_prob[idx][1]])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "apple-rotten-vgg16.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('tf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f1dd91301593ed57a3aa6ced3c8686829355a16df367190aff0744e5984c2469"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
